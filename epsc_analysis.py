# -*- coding: utf-8 -*-
"""EPSC_analysis.ipynb

Automatically generated by Colaboratory.

"""
#%%
!pip install plotly==4.14.3
#%%
!pip install chart-studio
#%%
# Next we want to install all packages and libraries we need for our analysis

from scipy.optimize import curve_fit

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from openpyxl import Workbook
from matplotlib.backends.backend_pdf import PdfPages
from sklearn.metrics import r2_score
#from scipy.stats import norm
import seaborn as sns
from scipy import stats
from statannot import add_stat_annotation
import os.path
import chart_studio.plotly as py

#%%
"""# Analysis of sE / IPSCs"""


"""---
# Firing rate and spike time irregularity
When we plot the output firing rate as a function of GWN mean or DC value, it is called the input-output transfer function of the neuron (so simply F-I curve).

Spike regularity can be quantified as the **coefficient of variance (CV) of the inter-spike-interval (ISI)**:
\begin{align}
\text{CV}_{\text{ISI}} = \frac{std(\text{ISI})}{mean(\text{ISI})}
\end{align}

A Poisson train is an example of high irregularity, in which $\textbf{CV}_{\textbf{ISI}} \textbf{= 1}$. And for a clocklike (regular) process we have $\textbf{CV}_{\textbf{ISI}} \textbf{= 0}$ because of **std(ISI)=0**.
"""
#%% Getting the data for IEI_CV


# IEI_data = pd.read_excel('24052020_WT_LC_0054Events.xlsx')
# #Take alook at the data
# IEI_data.head()
# EPSC_IEI= pd.DataFrame(IEI_data, columns=['Inter-event interval'])
# EPSC_IEI_CV = np.std(EPSC_IEI)/np.mean(EPSC_IEI)

# EPSC_IEI.hist(bins =30, grid=False, label='IEI_CV: %.2f' %EPSC_IEI_CV)
              
# plt.xlabel('(ms)')
# plt.ylabel('Frequency')
# plt.legend()
# plt.savefig('IEI.svg')
# plt.savefig('IEI.png')




#%% TAKE A LOOK AT THE DATA FIRST note: SHOULD BE BASELINED TO ZERO IN "STIMFIT"
save_path = r'C:\Users\shossein\Desktop\New folder\2020\December\07.12.2020\Cell_1\EPSC'

path = save_path + '/0017_events_before.xlsx'
data = pd.read_excel(path, skiprows=11) # define how many rows you want to ignore by looking at the data

#%% Defining the monoexponential function
 

# function for single exponential on kinetics NOTE :WHEN USING MULTIPLICATION REMEMBER TO DEVIDE THE TAU
def func_exp_1(x, a, b, c):
   return a * -np.exp(-x * b) + c
#%%
# half = np.float64(((min_peak_value-baseline)/2.0) + baseline)
# def lin_interp(x, y, i, half):
#     return x[i] + (x[i+1] - x[i]) * ((half - y[i]) / (y[i+1] - y[i]))

#Defibning the function to get the half maximum
# def half_max_x(x, y):
#     half= np.min(y)/2.0
#     signs = np.sign(np.add(y, -(half+half/2)))
#     zero_crossings = (signs[0:-2] != signs[1:-1])
#     zero_crossings_i = np.where(zero_crossings)[0]
#     return [lin_interp(x, y, zero_crossings_i[0], half),
#             lin_interp(x, y, zero_crossings_i[1], half)]
#%% # smooth the data using convolution
# def smooth(y, box_pts):
#     box = np.ones(box_pts)/box_pts
#     y_smooth = np.convolve(y, box, 'same')
#     return y_smooth
# # trace= [smooth(trace[:part],30) : trace[part:]]
# plt.plot(time, trace)
# plt.plot(time, smooth(trace,10), 'r-', lw=2)


#%% Looking at some examples
time = data.iloc[:,0] * 1e3  # first column is time

# Dividing time into different windows (=part) in order to find the peaks
part = len(time)//3  #usually for 30ms 7 windows
#Define the path for the data 

Rsquares_ON = []  # list of on r2 square
Rsquares_OFF = []  # list of off r2 square
Rsquares_ON_selected = []  # list of on r2 square
Rsquares_OFF_selected = []  # list of off r2 square
taus_ON = []  # list of on fit parameters tau
taus_OFF = [] # list of off fit parameters tau
taus_ON_selected = [] # list of on fit parameters tau
taus_OFF_selected = [] # list of off fit parameters tau
amplitudes = []


for idx, column in enumerate(data.iloc[:,1:20]):                 # first column is time ######ADJUST THE SECOND COLUMN####

        trace =data[column]
        min_peak_value = np.min(trace[part:2*part]) # change according to your window size 2 less for 8 window size
        min_peak = np.where(trace==min_peak_value)[0][0]
        baseline= np.mean(trace[:min_peak-part])
        ###window sizes for analysis
        #window size for analysis: based on the traces we use an optimal window that 
        #captures the kinetics of the events usually 2ms for tau_ON and double sized window for tau_OFF
        tau_ON_win= min_peak-part
        tau_OFF_win= min_peak+part
        ON_time = time[tau_ON_win:min_peak]  # reversing time to fit the exponetial from bottom to up  
        ON_time = ON_time[::-1]                                             # shift the axes to fit the exponential from right to left
        ON_trace =trace[tau_ON_win:min_peak]
        OFF_time = time[min_peak:tau_OFF_win]
        OFF_trace = trace[min_peak:tau_OFF_win]
        
        
        # the initial parameters
        p0 = [np.abs(min_peak_value), np.abs(time[min_peak]), 0.00001]
        
        
        popt1_c, pcov1_c = curve_fit(func_exp_1, ON_time, ON_trace, p0,  maxfev = 100000) #
        yhat_on_c = func_exp_1(ON_time, *popt1_c)
        Rsquare_ON = r2_score(ON_trace, yhat_on_c)# R_square
        popt1 = popt1_c # putting all fit parametrs into one array
        popt1_tau =  1/popt1_c[1] # putting all taus into one array
        taus_ON.append(popt1_tau)
        Rsquares_ON.append(Rsquare_ON)
        
        fig1 = plt.figure(figsize=(10, 6))
        plt.plot(time, trace)
  
        plt.plot(time[tau_ON_win:min_peak], func_exp_1(ON_time, *popt1), 'r-', label='fit: tau_on=%5.5f  R2=%5.5f' % (popt1_tau, Rsquare_ON))

        popt2_c, pcov2_c = curve_fit(func_exp_1, OFF_time, OFF_trace, p0, maxfev = 100000) #
        yhat2_c = func_exp_1(OFF_time, *popt2_c) 
        Rsquare_OFF = r2_score(OFF_trace, yhat2_c)
        popt2 = popt2_c # putting all fit parametrs into one array
        popt2_tau = 1/popt2_c[1] # putting all taus into one array
        taus_OFF.append(popt2_tau)
        Rsquares_OFF.append(Rsquare_OFF)
        plt.plot(time[min_peak:tau_OFF_win], func_exp_1(OFF_time, *popt2), 'g-', label='fit: tau_off=%5.5f  R2=%5.5f' % (popt2_tau, Rsquare_OFF))
        amplitudes.append(min_peak_value-baseline)                 # find the peak of the amplitude

    
        plt.legend()
        plt.xlabel('Time (ms)')
        plt.ylabel('(pA)')
        plt.title('Trace: %d' %idx)
        plt.plot(time[min_peak],min_peak_value,'or', )
        plt.annotate('Peak Amplitude: %d' %(min_peak_value-baseline), [time[min_peak],min_peak_value] )
        
        #plotting selected figures for ON
        if  popt1_tau < 10 and  popt1_tau > 0 and Rsquare_ON > 0.6 and min_peak_value-baseline < -10:
            fig2 = plt.figure(figsize=(10, 6))
            plt.plot(time, trace)
            plt.plot(time[tau_ON_win:min_peak], func_exp_1(ON_time, *popt1), 'r-', label='fit: tau_on=%5.5f  R2=%5.5f' % (popt1_tau, Rsquare_ON))
            plt.plot(time[min_peak:tau_OFF_win], func_exp_1(OFF_time, *popt2), 'g-', label='fit: tau_off=%5.5f  R2=%5.5f' % (popt2_tau, Rsquare_OFF))
            
            
            plt.legend()
            plt.xlabel('Time (ms)')
            plt.ylabel('(pA)')
            plt.title('Trace_ON_selected: %d' %idx)
            plt.plot(time[min_peak],min_peak_value,'or', )
            plt.annotate('Peak Amplitude: %d' %(min_peak_value-baseline), [time[min_peak],min_peak_value] )


          #plotting selected figures for OFF  
        if  popt2_tau < 100 and  popt2_tau > 0 and Rsquare_OFF > 0.6 and min_peak_value-baseline < -10:
            fig3 = plt.figure(figsize=(10, 6))
            plt.plot(time, trace)
            plt.plot(time[tau_ON_win:min_peak], func_exp_1(ON_time, *popt1), 'r-', label='fit: tau_on=%5.5f  R2=%5.5f' % (popt1_tau, Rsquare_ON))
            plt.plot(time[min_peak:tau_OFF_win], func_exp_1(OFF_time, *popt2), 'g-', label='fit: tau_off=%5.5f  R2=%5.5f' % (popt2_tau, Rsquare_OFF))
            
            
            plt.legend()
            plt.xlabel('Time (ms)')
            plt.ylabel('(pA)')
            plt.title('Trace_OFF_selected: %d' %idx)
            plt.plot(time[min_peak],min_peak_value,'or', )
            plt.annotate('Peak Amplitude: %d' %(min_peak_value-baseline), [time[min_peak],min_peak_value] )


    


        
       

#%% Time is in the first column of the data sheet
time = data.iloc[:,0] * 1e3

# Dividing time into different windows (=part) in order to find the peaks
part = len(time)//3  #usually for 30ms 7 windows
#Define the path for the data 


#Create workbook object
wb = Workbook()
sheet = wb.active
sheet.title='sEPSCs results'

#Generate data

#Add titles in the first row of each column
sheet.cell(row=1, column=1).value='Taus_ON'
sheet.cell(row=1, column=2).value='Rsqaures_ON'
sheet.cell(row=1, column=3).value='Taus_ON_selected'
sheet.cell(row=1, column=4).value='Taus_OFF'
sheet.cell(row=1, column=5).value='Rsquares_OFF'
sheet.cell(row=1, column=6).value='Taus_OFF_selected'
sheet.cell(row=1, column=7).value='Amplitude (pA)'
sheet.cell(row=1, column=8).value='Amplitude_selected (pA)'



# The PDF document
pdf_pages_all = PdfPages(os.path.join(save_path ,'fit_results_before.pdf'))
pdf_pages_ON_selected = PdfPages(os.path.join(save_path ,'fit_results_ON_selected_before.pdf'))
pdf_pages_OFF_selected = PdfPages(os.path.join(save_path ,'fit_results_OFF_selected_before.pdf'))
# pdf_pages = PdfPages(path + 'fit_results.pdf')


Rsquares_ON = []  # list of on r2 square
Rsquares_OFF = []  # list of off r2 square
Rsquares_ON_selected = []  # list of on r2 square
Rsquares_OFF_selected = []  # list of off r2 square



taus_ON = []  # list of on fit parameters tau
taus_OFF = [] # list of off fit parameters tau
taus_ON_selected = [] # list of on fit parameters tau
taus_OFF_selected = [] # list of off fit parameters tau
amplitudes = []
amplitudes_selectedd = []
columnn =[]

for idx, column in enumerate(data.iloc[:,1:20]):                 # first column is time


        trace =data[column]
        min_peak_value = np.min(trace[part:2*part])  # change according to your window size 2 less for 8 window size
        min_peak = np.where(trace==min_peak_value)[0][0]
        baseline= np.mean(trace[:min_peak-part])
        ###window sizes for analysis
        #window size for analysis: based on the traces we use an optimal window that 
        #captures the kinetics of the events usually 2ms for tau_ON and double sized window for tau_OFF
        tau_ON_win= min_peak-part
        tau_OFF_win= min_peak+part



        ON_time = time[tau_ON_win:min_peak]  # reversing time to fit the exponetial from bottom to up  
        ON_time = ON_time[::-1]                                             # shift the axes to fit the exponential from right to left
        ON_trace =trace[tau_ON_win:min_peak]
        OFF_time = time[min_peak:tau_OFF_win]
        OFF_trace = trace[min_peak:tau_OFF_win]
        
        # the initial parameters
        p0 = [np.abs(min_peak_value), np.abs(time[min_peak]), 0.001]
        popt1_c, pcov1_c = curve_fit(func_exp_1, ON_time, ON_trace, p0,  maxfev = 10000) #
        yhat_on_c = func_exp_1(ON_time, *popt1_c)
        Rsquare_ON = r2_score(ON_trace, yhat_on_c)# R_square
        popt1 = popt1_c # putting all fit parametrs into one array
        popt1_tau =  1 / popt1_c[1] # putting all taus into one array NOTE: DIVIDE IF FIT IS MULTIPLICATION
        taus_ON.append(popt1_tau)
        Rsquares_ON.append(Rsquare_ON)
        # getting the ACCEPTED values for Excell File 
        if  popt1_tau < 10 and  popt1_tau > 0 and Rsquare_ON > 0.6 and min_peak_value-baseline <  -10:
                taus_ON_selectedd = popt1_tau
                Rsquares_ON_selectedd = Rsquares_ON
                columnn.append(idx)
        else: 
                taus_ON_selectedd = 0
                Rsquares_ON_selectedd = 0
                
        # Getting the whole values for graphing
        if  popt1_tau < 10 and  popt1_tau > 0 and Rsquare_ON > 0.6 and min_peak_value-baseline < -10:
                taus_ON_selected.append(popt1_tau)
                Rsquares_ON_selected.append(Rsquare_ON)
        else: 
                taus_ON_selected.append(0)
                Rsquares_ON_selected.append(0)
        
        fig1 = plt.figure(figsize=(10, 6))
        plt.plot(time, trace)
        plt.plot(time[tau_ON_win:min_peak], func_exp_1(ON_time, *popt1), 'r-', label='fit: tau_on=%5.5f  R2=%5.5f' % (popt1_tau, Rsquare_ON))
            

    

        # the initial parameters
        # p0_OFF = [np.min(OFF_trace), np.min(OFF_time), 0.1]
        
        popt2_c, pcov2_c = curve_fit(func_exp_1, OFF_time, OFF_trace, p0, maxfev = 10000) #
        yhat2_c = func_exp_1(OFF_time, *popt2_c) 
        Rsquare_OFF = r2_score(OFF_trace, yhat2_c)
  
        popt2 = popt2_c # putting all fit parametrs into one array
        popt2_tau = 1 / popt2_c[1] # putting all taus into one array
        

        taus_OFF.append(popt2_tau)
        Rsquares_OFF.append(Rsquare_OFF)
        
    # getting the values for Excell File we set the cut off for tau OFF < 5 ms
        if  popt2_tau < 100 and  popt2_tau > 0 and Rsquare_OFF > 0.6 and min_peak_value-baseline < -10:
                taus_OFF_selectedd = popt2_tau
                Rsquares_OFF_selectedd = Rsquares_OFF
        else: 
                taus_OFF_selectedd = 0
                Rsquares_OFF_selectedd = 0
        
        if  popt2_tau < 100 and  popt2_tau > 0 and Rsquare_OFF > 0.6 and min_peak_value-baseline < -10:
                taus_OFF_selected.append(popt2_tau)
                Rsquares_OFF_selected.append(Rsquare_OFF)
        else: 
                taus_OFF_selected.append(0)
                Rsquares_OFF_selected.append(0)
        

        plt.plot(time[min_peak:tau_OFF_win], func_exp_1(OFF_time, *popt2), 'g-', label='fit: tau_off=%5.5f  R2=%5.5f' % (popt2_tau, Rsquare_OFF))
            



        amplitudes.append(min_peak_value-baseline)                 # find the peak of the amplitude
        

        if min_peak_value-baseline < -10:                           # find the peak of the selcted amplitude
            amplitudes_selectedd.append(min_peak_value-baseline)
        else:
            amplitudes_selectedd.append(0)
            
        if min_peak_value-baseline < -10:                           # find the peak of the selcted amplitude
            amplitudes_selected = min_peak_value-baseline
        else:
            amplitudes_selected = 0

        plt.legend()
        plt.xlabel('Time (ms)')
        plt.ylabel('(pA)')
        plt.title('Trace: %d' %idx)
        plt.plot(time[min_peak],min_peak_value,'or', )
        plt.annotate('Peak Amplitude: %d' %(min_peak_value-baseline), [time[min_peak],min_peak_value] )
    
        #FWHM
        # find the two crossing points
        # hmx = half_max_x(np.float64(time), np.float64(trace))
        # print the answer
        # fwhm = hmx[1] - hmx[0]
        # print("FWHM:{:.3f}".format(fwhm))
        # half = np.float64(((min_peak_value-baseline)/2.0) + baseline)
        # plt.plot(hmx, [half, half], '--k')
        # plt.annotate('FWHM: %.3f' %(fwhm), [hmx[1], half] )
        
        #plotting selected figures for ON
        if  popt1_tau < 10 and  popt1_tau > 0 and Rsquare_ON > 0.6 and min_peak_value-baseline < -10:
            fig2 = plt.figure(figsize=(10, 6))
            plt.plot(time, trace)
            plt.plot(time[tau_ON_win:min_peak], func_exp_1(ON_time, *popt1), 'r-', label='fit: tau_on=%5.5f  R2=%5.5f' % (popt1_tau, Rsquare_ON))
            plt.plot(time[min_peak:tau_OFF_win], func_exp_1(OFF_time, *popt2), 'g-', label='fit: tau_off=%5.5f  R2=%5.5f' % (popt2_tau, Rsquare_OFF))
            
            
            plt.legend()
            plt.xlabel('Time (ms)')
            plt.ylabel('(pA)')
            plt.title('Trace_ON_selected: %d' %idx)
            plt.plot(time[min_peak],min_peak_value,'or', )
            plt.annotate('Peak Amplitude: %d' %(min_peak_value-baseline), [time[min_peak],min_peak_value] )
            pdf_pages_ON_selected.savefig(fig2)

            
            
          #plotting selected figures for OFF  
        if  popt2_tau < 100 and  popt2_tau > 0 and Rsquare_OFF > 0.6 and min_peak_value-baseline < -10:
            fig3 = plt.figure(figsize=(10, 6))
            plt.plot(time, trace)
            plt.plot(time[tau_ON_win:min_peak], func_exp_1(ON_time, *popt1), 'r-', label='fit: tau_on=%5.5f  R2=%5.5f' % (popt1_tau, Rsquare_ON))
            plt.plot(time[min_peak:tau_OFF_win], func_exp_1(OFF_time, *popt2), 'g-', label='fit: tau_off=%5.5f  R2=%5.5f' % (popt2_tau, Rsquare_OFF))
            
            
            plt.legend()
            plt.xlabel('Time (ms)')
            plt.ylabel('(pA)')
            plt.title('Trace_OFF_selected: %d' %idx)
            plt.plot(time[min_peak],min_peak_value,'or', )
            plt.annotate('Peak Amplitude: %d' %(min_peak_value-baseline), [time[min_peak],min_peak_value] )
            pdf_pages_OFF_selected.savefig(fig3)
        
        pdf_pages_all.savefig(fig1)
        
        # plt.savefig('' + str(idx) + '.svg')

        #Loop to set the value of each cell
        sheet.cell(row=idx+2, column=1).value= popt1[1]                   #
        sheet.cell(row=idx+2, column=2).value= Rsquare_ON                   #
        sheet.cell(row=idx+2, column=3).value= taus_ON_selectedd                   #array with products
        sheet.cell(row=idx+2, column=4).value= popt2[1]                   #
        sheet.cell(row=idx+2, column=5).value= Rsquare_OFF                   #
        sheet.cell(row=idx+2, column=6).value= taus_OFF_selectedd                   #array with products
        sheet.cell(row=idx+2, column=7).value= min_peak_value

        #Finally, save the file and give it a name
        wb.save(os.path.join(save_path ,'fit_results_initial_before.xlsx'))
        
pdf_pages_all.close()
pdf_pages_ON_selected.close()
pdf_pages_OFF_selected.close()

dataa=[]
fig3 = plt.figure(figsize=(10, 6))
for columnn, column in enumerate(data.iloc[:,1:20]):
    trace =data[column]
    
    a= plt.plot(time, trace)
    dataa.append(a)
fig4 = plt.figure(figsize=(10, 6))
py.iplot(dataa, filename='2-curves')
#%% plotting Tau_ON against R2 with outliers (all tauS)
plt.scatter(taus_ON, Rsquares_ON, s=0.1)
plt.title('all Tau_ON')
plt.xlabel('Tau on')
plt.ylabel('R2_Square')
plt.savefig('tau_on.svg')
plt.savefig('tau_on.pdf')



#%% plotting Tau_ON against R2 without outliers (<1)
median_ON= np.median([x for x in taus_ON_selected if x !=0])
plt.scatter([x for x in taus_ON_selected if x !=0], [x for x in Rsquares_ON_selected if x !=0], 
            label='Median: %.3f' %median_ON, s=0.1)

plt.title('selected Tau_ON')
plt.xlabel('Tau on')
plt.ylabel('R2_Square')
plt.savefig('tau_on_selected.svg')
plt.savefig('tau_on_selected.pdf')
plt.legend()


#%% plotting Tau_OFF against R2 with outliers (all tauS)

plt.scatter(taus_OFF, Rsquares_OFF, s= 0.1)
plt.title('all Tau_OFF')
plt.xlabel('Tau off')
plt.ylabel('R2_Square')
plt.savefig('tau_off.svg')
plt.savefig('tau_off.pdf')

#%% plotting Tau_OFF against R2 with outliers (<2)
median_OFF= np.median([x for x in taus_OFF_selected if x !=0])
plt.scatter([x for x in taus_OFF_selected if x !=0], [x for x in Rsquares_OFF_selected if x !=0], 
            label='Median: %.3f' %median_OFF, s= 0.1)
plt.title('selected Tau_OFF')
plt.xlabel('Tau off')
plt.ylabel('R2_Square')
plt.savefig('tau_off_selected.svg')
plt.savefig('tau_off_selected.pdf')
plt.legend()



#%% Tau on density function
final_list_ON = taus_ON

plt.hist(final_list_ON, bins= 300, density= True, label="Samples Hist", alpha = 0.8)
plt.title('Tau_ON density')
plt.xlabel('ms')
plt.ylabel('frequency')


plt.savefig('tau_on_density.svg')
plt.savefig('tau_on_density.pdf')

#%% I fitt normal distribution to the data and calculate pdf.
# final_list_ON_selected = [x for x in taus_ON_selected if x !=0]
# mu_ON, sigma_ON = norm.fit(final_list_ON_selected)
# points_ON = np.linspace(norm.ppf(0.01,loc=mu_ON,scale=sigma_ON),
#                   norm.ppf(0.9999,loc=mu_ON,scale=sigma_ON),100)
# pdf_ON = norm.pdf(points_ON,loc=mu_ON,scale=sigma_ON)
#%% Tau on density function
final_list_ON_selected = [x for x in taus_ON_selected if x !=0]
median_ON= np.median([x for x in taus_ON_selected if x !=0])

plt.hist(final_list_ON_selected, bins= 300, density= True, 
         label = 'Median: %.3f' %median_ON,
         alpha = 0.8)
plt.title('Tau_ON density')
plt.xlabel('ms')
plt.ylabel('frequency')
# plt.plot(points_ON,pdf_ON, label='norm_PDF')


plt.savefig('tau_on_density_selected.svg')
plt.savefig('tau_on_density_selected.pdf')
plt.legend()
#%% Tau OFF density function
final_list_OFF = taus_OFF

plt.hist(final_list_OFF, bins= 300, density= True, label="Samples Hist", alpha = 0.8)
plt.title('Tau_OFF density')
plt.xlabel('ms')
plt.ylabel('frequency')


plt.savefig('tau_off_density.svg')
plt.savefig('tau_off_density.pdf')

#%% I fitt normal distribution to the data and calculate pdf.
# final_list_OFF_selected = [x for x in taus_OFF_selected if x !=0]
# mu_OFF, sigma_OFF = norm.fit(final_list_OFF_selected)
# points_OFF = np.linspace(norm.ppf(0.01,loc=mu_OFF,scale=sigma_OFF),
#                   norm.ppf(0.9999,loc=mu_OFF,scale=sigma_OFF),100)
# pdf_OFF = norm.pdf(points_OFF,loc=mu_OFF,scale=sigma_OFF)
#%% Tau OFF density function
final_list_OFF_selected = [x for x in taus_OFF_selected if x !=0]
median_OFF= np.median([x for x in taus_OFF_selected if x !=0])

plt.hist(final_list_OFF_selected, bins= 300, density= True, label='Median: %.3f' %median_OFF, alpha = 0.8)
plt.title('Tau_OFF density')
plt.xlabel('ms')
plt.ylabel('frequency')
# plt.plot(points_OFF,pdf_OFF, label='norm_PDF')

plt.legend()
plt.savefig('tau_off_density_selected.svg')
plt.savefig('tau_off_density_selected.pdf')

#%% Selected Amplitude

plt.hist(amplitudes_selectedd, bins= 300, density= True, label="Samples Hist", alpha = 0.8)
plt.title('Selected amplitudes')
plt.xlabel('Amplitude (pA)')
plt.ylabel('frequency')


plt.savefig('Selected_amplitude.svg')
plt.savefig('Selected_amplitude.pdf')
#%%
final_amplitudes_selectedd = [x for x in amplitudes_selectedd if x !=0]
median_amplitude= np.median([x for x in amplitudes_selectedd if x !=0])

plt.hist(final_amplitudes_selectedd, bins= 300, density= True, 
         label = 'Median: %.3f' %median_amplitude,
         alpha = 0.8)
plt.title('selected amplitudes density')
plt.xlabel('Amplitude (pA)')
plt.ylabel('frequency')
# plt.plot(points_ON,pdf_ON, label='norm_PDF')


plt.savefig('Selected_amplitude_density.svg')
plt.savefig('Selected_amplitude_density.pdf')
plt.legend()


#%% sEPSC final
sEPSC_mean = pd.read_excel('all_sEPSC_WT_LC.xlsx', sheet_name='Sheet1')

Tau_ON= pd.DataFrame(sEPSC_mean, columns= ['Taus_ON_selected'])
Tau_OFF= pd.DataFrame(sEPSC_mean, columns= ['Taus_OFF_selected'])
Amplitude= pd.DataFrame(sEPSC_mean, columns= ['Amplitude_selected (pA)'])



f, axes = plt.subplots(1, 3, figsize=(10,8))
sns.set_style('ticks')
ax = box_plot = sns.boxplot(palette=['#BBBBBB','#DDDDDD'],linewidth=2,data= Tau_ON, ax=axes[0])
medians = round(np.median(Tau_ON),3)
vertical_offset = np.median(Tau_ON) * 0.5 # offset from median for display
ax.text(0.2,medians + vertical_offset,medians, 
horizontalalignment='center',fontsize=15,color='k',weight='semibold')

ax = sns.swarmplot(data= Tau_ON, color="black", 
                  palette=sns.color_palette(),
                  edgecolor='black',
                  linewidth=5,
                  ax=axes[0])

# FIRST COMMENT THEN ADUST
ax.set(ylim=(0, 6))


ax = box_plot = sns.boxplot(palette=['#BBBBBB','#DDDDDD'],linewidth=2,data= Tau_OFF, ax=axes[1])
medians = round(np.median(Tau_OFF),3)
vertical_offset = np.median(Tau_OFF) * 0.5 # offset from median for display
ax.text(0.2,medians + vertical_offset,medians, 
horizontalalignment='center',fontsize=15,color='k',weight='semibold')

ax = sns.swarmplot(data= Tau_OFF, color="black", 
                  palette=sns.color_palette(),
                  edgecolor='black',
                  linewidth=5,
                  ax=axes[1])


# FIRST COMMENT THEN ADUST
ax.set(ylim=(0, 6))



ax = box_plot = sns.boxplot(palette=['#BBBBBB','#DDDDDD'],linewidth=2,data= Amplitude, ax=axes[2])
medians = round(np.median(Amplitude),3)
vertical_offset = np.median(Amplitude) * 0.5 # offset from median for display
ax.text(0.2,medians + vertical_offset,medians, 
horizontalalignment='center',fontsize=15,color='k',weight='semibold')

ax = sns.swarmplot(data= Amplitude, color="black", 
                  palette=sns.color_palette(),
                  edgecolor='black',
                  linewidth=5,
                  ax=axes[2])

# FIRST COMMENT THEN ADUST
ax.set(ylim=(0, -25))





sns.despine(offset=10,trim=True)

f.tight_layout()

plt.savefig('sEPSC_features_WT_LC.svg')
plt.savefig('sEPSC_features_WT_LC.pdf')


#%% Averaged results Heat map of the mean ONLY sEPSC
# Before

all_mean_b = pd.read_excel('Book1.xlsx', sheet_name='Rich_enviornment')
all_mean_b['mean_b'] = stats.zscore(all_mean_b['mean_b']) # Compute the z score of each value in the sample, relative to the sample mean and standard deviation.
all_mean_b =all_mean_b.pivot('Cell', 'window', 'mean_b')

#PLOTTING Heatmap
plt.figure(figsize=(10, 6))
all_mean_b_fig = sns.heatmap(all_mean_b)
plt.title('IEI mean before stimulus (5second)')
sns.color_palette("rocket")
plt.savefig('Rich_EPSC_mean_b.svg')
plt.savefig('Rich_EPSC_mean_b.pdf')

# after
all_mean_a = pd.read_excel('Book1.xlsx', sheet_name='Rich_enviornment')
all_mean_a['mean_a'] = stats.zscore(all_mean_a['mean_a']) # Compute the z score of each value in the sample, relative to the sample mean and standard deviation.
all_mean_a =all_mean_a.pivot('Cell', 'window', 'mean_a')

#PLOTTING Heatmap
plt.figure(figsize=(10, 6))
all_mean_a_fig = sns.heatmap(all_mean_a)
plt.title('IEI mean after stimulus (5second)')
sns.color_palette("rocket")
plt.savefig('Rich_EPSC_mean_a.svg')
plt.savefig('Rich_EPSC_mean_a.pdf')



#%%
# POINT plot FOE eEPSC  



EPSC_rate1 = pd.read_excel('all.xlsx', sheet_name='Rich_enviornment_event_mean')
# EPSC_rate2 = pd.read_excel('all.xlsx', sheet_name='WT_event_mean')

plt.figure(figsize=(10, 3))
sns.set_style('white')

ax = sns.pointplot(x= 'windows', y= 'mean', data= EPSC_rate1, join=True, color='green')
# axx = sns.swarmplot(x= 'windows', y= 'mean', data= EPSC_rate1, 
#                   color='GREEN',
#                     linewidth=0.1)

ax1 = sns.pointplot(x= 'windows', y= 'mean', data= EPSC_rate2, join=True, color='red')
# axx1 = sns.swarmplot(x= 'windows', y= 'mean', data= EPSC_rate2, 
#                   color='red',
#                   linewidth=0.1)
# ax = sns.pointplot(x= 'window', y= 'mean', data= EPSC_rate, color="black", 
#                   jitter=0.35,
#                   palette=sns.color_palette(),
#                   edgecolor='black',
#                   linewidth=0.1)
# add_stat_annotation(ax, x= 'windows', y= 'mean', data= EPSC_rate1, 
#                     box_pairs=[('win5','win6')
                    #             ],
                    # test='t-test_paired', text_format='star', loc='inside', verbose=2)
plt.tight_layout()
plt.xlabel('Frequency (Hz)')
plt.title('EPSC_event compare')
plt.savefig('EPSC_mean_event_box.svg')
plt.savefig('EPSC_mean_event_box.pdf')

#%% Z_score with SEM
from matplotlib import pyplot as plt
import numpy as np

all_mean_b1 = pd.read_excel('all.xlsx', sheet_name='WT_amp')
all_mean_b2 = pd.read_excel('all.xlsx', sheet_name='EE_amp')
# all_mean_b['mean_b'] = stats.zscore(all_mean_b['mean_b']) 
all_mean_b1 =all_mean_b1.pivot('Cell', 'window', 'mean_a')
all_mean_b2 =all_mean_b2.pivot('Cell', 'window', 'mean_a')
plt.figure(figsize=(20, 2))

ax1 = sns.pointplot( data= all_mean_b1, join=True, color='GREEN')
ax2 = sns.pointplot( data= all_mean_b2, join=True, color='red')
plt.ylim(-30, -10)
# axes.set(ylim=(0, 30))
plt.xlabel('EPSC amplitude (pA)')
# plt.title('after EPSC_IEI')

plt.savefig('EPSC_amp_Aftr.svg')
plt.savefig('EPSC_amp_Aftr.pdf')


# x1 = [1, 2, 3, 4, 5]
# y1 = np.mean(all_mean_b).tolist()
# error1 = stats.sem(all_mean_b)
# # y += np.random.normal(0, 0.1, size=y.shape)

# plt.plot(x1, y1, 'k-')
# plt.fill_between(x1, y1-error1, y1+error1,color= 'gray')

# # plt.savefig('WT_event_before.svg')
# # plt.savefig('WT_event_before.pdf')
# # plt.show()




# all_mean_a = pd.read_excel('all.xlsx', sheet_name='WT_event')
# all_mean_a['mean_a'] = stats.zscore(all_mean_a['mean_a'])
# all_mean_a =all_mean_a.pivot('Cell', 'window', 'mean_a') 

# x2 = [6, 7, 8, 9, 10]
# y2 = np.mean(all_mean_a).tolist()
# error2 = stats.sem(all_mean_a)
# # y += np.random.normal(0, 0.1, size=y.shape)

# plt.plot(x2, y2, 'k-')
# plt.fill_between(x2, y2-error2, y2+error2, color= 'gray')
# # plt.savefig('WT_event_after.svg')
# # plt.savefig('WT_event_after.pdf')
# # plt.show()


#%% Zscore vs time sereies


x = np.concatenate((x1,x2))
y = np.concatenate((y1,y2))
error = np.concatenate((error1,error2))
# y += np.random.normal(0, 0.1, size=y.shape)

plt.plot(x, y, 'k-')
plt.fill_between(x, y-error, y+error, color= 'gray')


plt.xlabel('Time (s)')
plt.ylabel('Z_score')
plt.title('Time_Series')
# plt.savefig('WT_ZScore.svg')
# plt.savefig('WT_ZScore.pdf')
# plt.show()
#%% averaged connecting point plots
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd


all_mean_b = pd.read_excel('all.xlsx', sheet_name='WT_event')
all_mean_b =all_mean_b.pivot('Cell', 'window', 'mean_b') 


all_mean_a = pd.read_excel('all.xlsx', sheet_name='WT_event')
all_mean_a =all_mean_a.pivot('Cell', 'window', 'mean_a')

# Event frequency
set1 = np.mean(all_mean_b, axis =1).tolist()
set2 = np.mean(all_mean_a, axis =1).tolist()

# Put into dataframe
df = pd.DataFrame({'Before Depolarization': set1, 'After Depolarization': set2})
data = pd.melt(df)

# Plot
fig, ax = plt.subplots()
sns.swarmplot(data=data, x='variable', y='value', ax=ax)

# Now connect the dots
# Find idx0 and idx1 by inspecting the elements return from ax.get_children()
# ... or find a way to automate it
idx0 = 0
idx1 = 1
locs1 = ax.get_children()[idx0].get_offsets()
locs2 = ax.get_children()[idx1].get_offsets()

for i in range(locs1.shape[0]):
    x = [locs1[i, 0], locs2[i, 0]]
    y = [set1[i], set2[i]]
    ax.plot(x, y, color='black', alpha=0.3)
    
add_stat_annotation(data=data, x='variable', y='value', ax=ax, 
                    box_pairs=[('Before Depolarization', 'After Depolarization')
                                ],
                    test='Mann-Whitney', text_format='star', loc='inside', verbose=2)   
    
# plt.xlabel('Time (s)')
plt.ylabel('IEI (ms)')
plt.title('Averaged enriched IEI (5 Seconds)')
# plt.savefig('Averaged enriched IEI.svg')
# plt.savefig('Averaged enriched IEI.pdf')
# plt.show()

#%% connecting point plots

all_mean_b = pd.read_excel('all.xlsx', sheet_name='EE_amp_mean')
all_mean_b =all_mean_b.pivot('Cell', 'window', 'mean_a') 
all_last_b = all_mean_b['Win_19']

all_mean_a = pd.read_excel('all.xlsx', sheet_name='EE_amp_mean')
all_mean_a =all_mean_a.pivot('Cell', 'window', 'mean_a')
all_first_a = all_mean_a['Win_29']
# Generate random data
set1 = all_last_b.tolist()
set2 = all_first_a.tolist()

# Put into dataframe
df = pd.DataFrame({'1s Bfr': set1, '1s Aftr': set2})
data = pd.melt(df)

# Plot
fig, ax = plt.subplots()
sns.swarmplot(data=data, x='variable', y='value', ax=ax)

# Now connect the dots
# Find idx0 and idx1 by inspecting the elements return from ax.get_children()
# ... or find a way to automate it
idx0 = 0
idx1 = 1
locs1 = ax.get_children()[idx0].get_offsets()
locs2 = ax.get_children()[idx1].get_offsets()

for i in range(locs1.shape[0]):
    x = [locs1[i, 0], locs2[i, 0]]
    y = [set1[i], set2[i]]
    ax.plot(x, y, color='black', alpha=0.3)
    
add_stat_annotation(data=data, x='variable', y='value', ax=ax, 
                    box_pairs=[('1s Bfr', '1s Aftr')
                                ],
                    test='Wilcoxon', text_format='star', loc='inside', verbose=2)   
    
# plt.xlabel('Time (s)')
plt.ylabel('EPSC amp (pA)')
plt.title('EE_60_70')
# plt.savefig('EE_event.svg')
plt.savefig('EE_amp_60_70.pdf')
plt.show()